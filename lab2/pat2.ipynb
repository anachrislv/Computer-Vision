{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ddefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cv23_lab2_2_utils import read_video, show_detection, orientation_histogram, bag_of_words, svm_train_test\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import ndimage as nd\n",
    "import cv2\n",
    "from scipy.ndimage import convolve1d\n",
    "import cv23_lab2_2_utils as utils\n",
    "from cv23_lab2_2_utils import read_video, show_detection, orientation_histogram, bag_of_words, svm_train_test\n",
    "\n",
    "import cv23_lab2_2_utils as utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "walking_dir = './cv23_lab2_material/part2 - SpatioTemporal/walking/'\n",
    "running_dir = './cv23_lab2_material/part2 - SpatioTemporal/running/'\n",
    "handwaving_dir = './cv23_lab2_material/part2 - SpatioTemporal/handwaving/'\n",
    "\n",
    "walk_videos = [os.path.join(walking_dir, filename) for filename in os.listdir(walking_dir)]\n",
    "run_videos = [os.path.join(running_dir, filename) for filename in os.listdir(running_dir)]\n",
    "hand_videos = [os.path.join(handwaving_dir, filename) for filename in os.listdir(handwaving_dir)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "walk_video1 = read_video(walk_videos[1], 200)\n",
    "run_video1 = read_video(run_videos[1], 200)\n",
    "wave_video1 = read_video(hand_videos[1], 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275afe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Out = \"processed_video1\"\n",
    "delta = 4\n",
    "theta = 1.5\n",
    "alpha = 2\n",
    "kappa = 0.005\n",
    "num_frames = 600\n",
    "\n",
    "num_kernel = int(2 * np.ceil(3 * delta) + 1)  # kernel size\n",
    "Gauss_1D = cv2.getGaussianKernel(num_kernel, delta)\n",
    "Gauss_1D = Gauss_1D.reshape(Gauss_1D.shape[0])\n",
    "Out_2 = convolve1d(Out, Gauss_1D, axis=0)\n",
    "\n",
    "Out_3 = convolve1d(Out_2, Gauss_1D, axis=1)\n",
    "\n",
    "num_kernel = int(2 * np.ceil(3 * theta) + 1)  # kernel size\n",
    "Gauss_t = cv2.getGaussianKernel(num_kernel, theta)\n",
    "Gauss_t = Gauss_t.reshape(Gauss_t.shape[0])\n",
    "Out_4 = convolve1d(Out_3, Gauss_t, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_time_Gaus(input_video, sigma_val, tau_val):\n",
    "    \n",
    "    num_kernel = int(2 * np.ceil(3 * sigma_val) + 1)  # kernel size\n",
    "    gauss_1d = cv2.getGaussianKernel(num_kernel, sigma_val)\n",
    "    gauss_2d = gauss_1d @ gauss_1d.transpose()\n",
    "    \n",
    "    # Reshaping the 2D Gaussian kernel to make it 3D\n",
    "    gauss_2d = gauss_2d.reshape(gauss_2d.shape[0], gauss_2d.shape[1], 1)\n",
    "    \n",
    "    # Creating a temporal Gaussian kernel\n",
    "    num_kernel = int(2 * np.ceil(3 * tau_val) + 1)  # kernel size\n",
    "    gauss_time = cv2.getGaussianKernel(num_kernel, tau_val)\n",
    "    # Reshaping the temporal Gaussian kernel to make it 3D\n",
    "    gauss_time = gauss_time.reshape(1, 1, gauss_time.shape[0])\n",
    "    \n",
    "    # Combining the three kernels\n",
    "    gauss_combined = nd.convolve(gauss_time, gauss_2d)\n",
    "    result = nd.convolve(input_video, gauss_combined)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def space_Gaus(input_video, sigma_val):\n",
    "    \n",
    "    num_kernel = int(2 * np.ceil(3 * sigma_val) + 1)  # kernel size\n",
    "    gauss_1d = cv2.getGaussianKernel(num_kernel, sigma_val)\n",
    "    gauss_2d = gauss_1d @ gauss_1d.transpose()\n",
    "    \n",
    "    # Reshaping the 2D Gaussian kernel to convolve with the video only in space (x, y)\n",
    "    gauss_2d = gauss_2d.reshape(gauss_2d.shape[0], gauss_2d.shape[1], 1)\n",
    "    \n",
    "    result = nd.convolve(input_video, gauss_2d)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Harris_Detector(input_data, parameter1, parameter2, parameter3, parameter4):\n",
    "    \n",
    "    input_data = input_data.astype(np.float32)\n",
    "    \n",
    "    L = transform_data(input_data, parameter1, parameter2)\n",
    "    \n",
    "    # Using a different table to calculate derivatives in one axis\n",
    "    dx = np.array([[[-1], [0], [1]]])\n",
    "    Lx = nd.convolve(L, dx)\n",
    "    # Changing the orientation of the table\n",
    "    dy = np.array([[[-1]], [[0]], [[1]]])\n",
    "    Ly = nd.convolve(L, dy)\n",
    "    # Changing the orientation of the table\n",
    "    dt = np.array([[[-1, 0, 1]]])\n",
    "    Lt = nd.convolve(L, dt)\n",
    "    \n",
    "    L = np.array([[Lx * Lx, Lx * Ly, Lx * Lt], [Lx * Ly, Ly * Ly, Ly * Lt], [Lx * Lt, Ly * Lt, Lt * Lt]])\n",
    "    \n",
    "    # Initializing the M table\n",
    "    M = L\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            M[i, j] = transform_data(L[i, j], parameter1 * parameter3, parameter2 * parameter3)\n",
    "    \n",
    "    trace = np.trace(M)\n",
    "    det = M[0, 0] * (M[1, 1] * M[2, 2] - M[1, 2] * M[2, 1]) - M[0, 1] * (M[1, 0] * M[2, 2] - M[1, 2] * M[2, 0]) \\\n",
    "        + M[0, 2] * (M[1, 0] * M[2, 1] - M[1, 1] * M[2, 0])\n",
    "    H = det - parameter4 * trace**3\n",
    "    \n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gabor_Detector(input_data, parameter1, parameter2):\n",
    "    \n",
    "    input_data = input_data.astype(np.float32)\n",
    "    \n",
    "    L = modified_space_Gaus(input_data, parameter1)\n",
    "    \n",
    "    w = 4 / parameter2\n",
    "    t = np.arange(-2 * parameter2, 2 * parameter2 + 1)\n",
    "    \n",
    "    h_ev = np.cos(2 * np.pi * t * w) * np.exp(-t ** 2 / (2 * parameter2 ** 2))\n",
    "    h_od = np.sin(2 * np.pi * t * w) * np.exp(-t ** 2 / (2 * parameter2 ** 2))\n",
    "    \n",
    "    # Normalization with L1 norm\n",
    "    h_ev = h_ev / np.linalg.norm(h_ev, ord=1)\n",
    "    h_od = h_od / np.linalg.norm(h_od, ord=1)\n",
    "    \n",
    "    H = convolve1d(L, h_ev) ** 2 + convolve1d(L, h_od) ** 2\n",
    "    \n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c54cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keypoints(H, num_points, sigma_val):\n",
    "    \n",
    "    max_points = np.dstack(np.unravel_index(np.argsort(H.ravel()), (H.shape[0], H.shape[1], H.shape[2])))\n",
    "    max_points = max_points.reshape(max_points.shape[1], max_points.shape[2])\n",
    "    max_points = max_points[-num_points:]\n",
    "    \n",
    "    keypoints = np.array([np.append(pair[:2][::-1], [pair[2], sigma_val]) for pair in max_points])\n",
    "        \n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Harris_points(input_data, sigma_val, tau_val, s_val, k_val, num_points):\n",
    "    H = Harris_Detector(input_data, sigma_val, tau_val, s_val, k_val)\n",
    "    keypoints = find_keypoints(H, num_points, sigma_val)\n",
    "    return keypoints\n",
    "\n",
    "def Gabor_points(input_data, sigma_val, tau_val, num_points):\n",
    "    H = Gabor_Detector(input_data, sigma_val, tau_val)\n",
    "    keypoints = find_keypoints(H, num_points, sigma_val)\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ee9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Input data\n",
    "In_walk = walk_video1\n",
    "In_wave = wave_video1\n",
    "In_run = run_video1\n",
    "\n",
    "# Parameters\n",
    "sigma = 4\n",
    "tau = 1.5\n",
    "s = 2\n",
    "k = 0.005\n",
    "N = 600\n",
    "\n",
    "# Harris Detector for walk video\n",
    "H_Harris_walk = Harris_Detector(In_walk, sigma, tau, s, k)\n",
    "# Gabor Detector for walk video\n",
    "H_Gabor_walk = Gabor_Detector(In_walk, sigma, tau)\n",
    "\n",
    "# Harris Detector for wave video\n",
    "H_Harris_wave = Harris_Detector(In_wave, sigma, tau, s, k)\n",
    "# Gabor Detector for wave video\n",
    "H_Gabor_wave = Gabor_Detector(In_wave, sigma, tau)\n",
    "\n",
    "# Harris Detector for run video\n",
    "H_Harris_run = Harris_Detector(In_run, sigma, tau, s, k)\n",
    "# Gabor Detector for run video\n",
    "H_Gabor_run = Gabor_Detector(In_run, sigma, tau)\n",
    "\n",
    "# Exporting data\n",
    "np.save('H_Harris_walk.npy', H_Harris_walk)\n",
    "np.save('H_Gabor_walk.npy', H_Gabor_walk)\n",
    "np.save('H_Harris_wave.npy', H_Harris_wave)\n",
    "np.save('H_Gabor_wave.npy', H_Gabor_wave)\n",
    "np.save('H_Harris_run.npy', H_Harris_run)\n",
    "np.save('H_Gabor_run.npy', H_Gabor_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca33d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "sigma = 4\n",
    "tau = 1.5\n",
    "s = 2\n",
    "k = 0.005\n",
    "N = 600\n",
    "\n",
    "\n",
    "\n",
    "# Harris Detector on walk video\n",
    "In = walk_video1\n",
    "keypoints_harris_walk = modified_Harris_points(In, sigma, tau, s, k, N)\n",
    "show_detection(In, keypoints_harris_walk, save_path='cv23_lab2_material/walk_harris')\n",
    "\n",
    "# Harris Detector on run video\n",
    "In = run_video1\n",
    "keypoints_harris_run = modified_Harris_points(In, sigma, tau, s, k, N)\n",
    "show_detection(In, keypoints_harris_run, save_path='cv23_lab2_material/run_harris')\n",
    "\n",
    "# Harris Detector on wave video\n",
    "In = wave_video1\n",
    "keypoints_harris_wave = modified_Harris_points(In, sigma, tau, s, k, N)\n",
    "show_detection(In, keypoints_harris_wave, save_path='cv23_lab2_material/wave_harris')\n",
    "\n",
    "# Gabor Detector on walk video\n",
    "In = walk_video1\n",
    "keypoints_gabor_walk = modified_Gabor_points(In, sigma, tau, N)\n",
    "show_detection(In, keypoints_gabor_walk, save_path='cv23_lab2_material/walk_gabor')\n",
    "\n",
    "# Gabor Detector on run video\n",
    "In = run_video1\n",
    "keypoints_gabor_run = modified_Gabor_points(In, sigma, tau, N)\n",
    "show_detection(In, keypoints_gabor_run, save_path='cv23_lab2_material/run_gabor')\n",
    "\n",
    "# Gabor Detector on wave video\n",
    "In = wave_video1\n",
    "keypoints_gabor_wave = modified_Gabor_points(In, sigma, tau, N)\n",
    "show_detection(In, keypoints_gabor_wave, save_path='cv23_lab2_material/wave_hof')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb20c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TVL1(previous_frame, current_frame):\n",
    "    optical_flow = cv2.DualTVL1OpticalFlow_create(nscales=1)\n",
    "    flow = optical_flow.calc(previous_frame, current_frame, None)\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ffaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_flow_TVL1(input_frames):\n",
    "    \n",
    "    input_frames = input_frames.astype(np.uint8)\n",
    "    \n",
    "    # Initializing np arrays for flow in x and y\n",
    "    flow_x = np.empty((input_frames.shape[0], input_frames.shape[1], input_frames.shape[2]))\n",
    "    flow_y = np.empty((input_frames.shape[0], input_frames.shape[1], input_frames.shape[2]))\n",
    "    \n",
    "    # Converting to uint8 type \n",
    "    \n",
    "    for t in range(input_frames.shape[2]):\n",
    "        \n",
    "        # If border\n",
    "        if t == input_frames.shape[2] - 1:\n",
    "            t = t - 1\n",
    "        \n",
    "        prev_frame = input_frames[:,:,t]\n",
    "        current_frame = input_frames[:,:,t+1]\n",
    "        \n",
    "        flow = compute_TVL1(prev_frame, current_frame)\n",
    "        \n",
    "        flow_x[:, :, t] = flow[:, :, 1]\n",
    "        flow_y[:, :, t] = flow[:, :, 0]\n",
    "        \n",
    "    return (flow_x, flow_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f72bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG(input_frames, interest_points, nbins=9, n=3, m=3):\n",
    "    \n",
    "    dy, dx, _ = np.gradient(input_frames)\n",
    "    \n",
    "    max_y = input_frames.shape[0]\n",
    "    max_x = input_frames.shape[1]\n",
    "    Y = []\n",
    "    \n",
    "    for point in interest_points:\n",
    "        \n",
    "        # Separating point's coordinates\n",
    "        x = point[0]\n",
    "        y = point[1]\n",
    "        t = point[2]\n",
    "        sigma = point[3]\n",
    "        \n",
    "        # Region 4*sigma around each interest point\n",
    "        side = int(np.round(4 * sigma))\n",
    "        \n",
    "        # Using ifs to avoid going out of image dimensions\n",
    "        if x - side <= 0:\n",
    "            x_left = 0\n",
    "        else:\n",
    "            x_left = x - side\n",
    "            \n",
    "        if x + side + 1 >= max_x:\n",
    "            x_right = max_x\n",
    "        else:\n",
    "            x_right = x + side + 1\n",
    "        \n",
    "        if y - side <= 0:\n",
    "            y_up = 0\n",
    "        else:\n",
    "            y_up = y - side\n",
    "            \n",
    "        if y + side + 1 >= max_y:\n",
    "            y_down = max_y\n",
    "        else:\n",
    "            y_down = y + side + 1\n",
    "    \n",
    "        \n",
    "        Gx = dx[y_up:y_down, x_left:x_right, t]\n",
    "        Gy = dy[y_up:y_down, x_left:x_right, t]\n",
    "        \n",
    "        Y.append(orientation_histogram(Gx, Gy, nbins, np.array([n,m])))\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0a364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOF(input_frames, interest_points, nbins=9, n=3, m=3):\n",
    "    \n",
    "    dx, dy = optical_flow_TVL1(input_frames)\n",
    "    \n",
    "    max_y = input_frames.shape[0]\n",
    "    max_x = input_frames.shape[1]\n",
    "    Y = []\n",
    "    \n",
    "    for point in interest_points:\n",
    "        \n",
    "        # Separating point's coordinates\n",
    "        x = point[0]\n",
    "        y = point[1]\n",
    "        t = point[2]\n",
    "        sigma = point[3]\n",
    "        \n",
    "        # Region 4*sigma around each interest point\n",
    "        side = int(np.round(4 * sigma))\n",
    "        \n",
    "        # Using ifs to avoid going out of image dimensions\n",
    "        if x - side <= 0:\n",
    "            x_left = 0\n",
    "        else:\n",
    "            x_left = x - side\n",
    "            \n",
    "        if x + side + 1 >= max_x:\n",
    "            x_right = max_x\n",
    "        else:\n",
    "            x_right = x + side + 1\n",
    "        \n",
    "        if y - side <= 0:\n",
    "            y_up = 0\n",
    "        else:\n",
    "            y_up = y - side\n",
    "            \n",
    "        if y + side + 1 >= max_y:\n",
    "            y_down = max_y\n",
    "        else:\n",
    "            y_down = y + side + 1\n",
    "        \n",
    "        Gx = dx[y_up:y_down, x_left:x_right, t]\n",
    "        Gy = dy[y_up:y_down, x_left:x_right, t]\n",
    "        \n",
    "        Y.append(orientation_histogram(Gx, Gy, nbins, np.array([n,m])))\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOF_HOG(In, interest_points, nbins=9, n=3, m=3):\n",
    "    hof = HOF(In, interest_points, nbins=nbins, n=n, m=m)\n",
    "    hog = HOG(In, interest_points, nbins=nbins, n=n, m=m)\n",
    "    return np.concatenate((hog, hof))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706937c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In = walk_video1\n",
    "sigma = 4\n",
    "tau = 1.5\n",
    "N = 600\n",
    "\n",
    "points = Gabor_points(In, sigma, tau, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dcfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_videos_txt = open('cv23_lab2_material/part2 - SpatioTemporal/training_videos.txt', 'r')\n",
    "training_videos_names = [line.strip() for line in training_videos_txt.readlines()]\n",
    "\n",
    "training_videos = []\n",
    "test_videos = []\n",
    "training_labels = []\n",
    "test_labels = []\n",
    "test_videos_names = []\n",
    "\n",
    "video_directory = 'cv23_lab2_material/part2 - SpatioTemporal/'\n",
    "\n",
    "walking_directory = os.path.join(video_directory, 'walking')\n",
    "handwaving_directory = os.path.join(video_directory, 'handwaving')\n",
    "running_directory = os.path.join(video_directory, 'running')\n",
    "\n",
    "# Load walking videos\n",
    "for video_name in os.listdir(walking_directory):\n",
    "    video_path = os.path.join(walking_directory, video_name)\n",
    "    if video_name in training_videos_names:\n",
    "        training_videos.append(read_video(video_path, 200))\n",
    "        training_labels.append('walk')\n",
    "    else:\n",
    "        test_videos.append(read_video(video_path, 200))\n",
    "        test_labels.append('walk')\n",
    "        test_videos_names.append(video_name)\n",
    "\n",
    "# Load handwaving videos\n",
    "for video_name in os.listdir(handwaving_directory):\n",
    "    video_path = os.path.join(handwaving_directory, video_name)\n",
    "    if video_name in training_videos_names:\n",
    "        training_videos.append(read_video(video_path, 200))\n",
    "        training_labels.append('handwaving')\n",
    "    else:\n",
    "        test_videos.append(read_video(video_path, 200))\n",
    "        test_labels.append('handwaving')\n",
    "        test_videos_names.append(video_name)\n",
    "\n",
    "# Load running videos\n",
    "for video_name in os.listdir(running_directory):\n",
    "    video_path = os.path.join(running_directory, video_name)\n",
    "    if video_name in training_videos_names:\n",
    "        training_videos.append(read_video(video_path, 200))\n",
    "        training_labels.append('run')\n",
    "    else:\n",
    "        test_videos.append(read_video(video_path, 200))\n",
    "        test_labels.append('run')\n",
    "        test_videos_names.append(video_name)\n",
    "\n",
    "training_videos = np.array(training_videos)\n",
    "test_videos = np.array(test_videos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_Harris_points_training = []\n",
    "desc_HOG_Harris_train = []\n",
    "sigma = 4\n",
    "tau = 1.5\n",
    "s = 2\n",
    "k = 0.005\n",
    "N = 600\n",
    "n = int(np.round(4 * sigma))\n",
    "m = int(np.round(4 * sigma))\n",
    "\n",
    "for Input in training_videos:\n",
    "    interest_points = Harris_points(Input, sigma, tau, s, k, N)\n",
    "    interest_Harris_points_training.append(interest_points)\n",
    "    desc = HOG(Input, interest_points, 9, n, m)\n",
    "    desc_HOG_Harris_train.append(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_Harris_points_test = []\n",
    "desc_HOG_Harris_test = []\n",
    "\n",
    "for Input in test_videos:\n",
    "    interest_points = Harris_points(Input, sigma, tau, s, k, N)\n",
    "    interest_Harris_points_test.append(interest_points)\n",
    "    desc = HOG(Input, interest_points, 9, n, m)\n",
    "    desc_HOG_Harris_test.append(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_HOG_Harris, bow_test_HOG_Harris = bag_of_words(desc_HOG_Harris_train, desc_HOG_Harris_test, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "desc_HOF_Harris_test = []\n",
    "for Input in test_videos:\n",
    "    desc = HOF(Input, interest_Harris_points_test[i], 9, n, m)\n",
    "    desc_HOF_Harris_test.append(desc)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words for Harris/HOF\n",
    "bow_train_HOF_Harris, bow_test_HOF_Harris = bag_of_words(desc_HOF_Harris_train, desc_HOF_Harris_test, 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris/HOF_HOG descriptors for training videos\n",
    "desc_HOF_HOG_Harris_train = []\n",
    "for i, Input in enumerate(training_videos):\n",
    "    desc = HOF_HOG(Input, interest_Harris_points_training[i], 9, n, m)\n",
    "    desc_HOF_HOG_Harris_train.append(desc)\n",
    "\n",
    "# Harris/HOF_HOG descriptors for test videos\n",
    "desc_HOF_HOG_Harris_test = []\n",
    "for i, Input in enumerate(test_videos):\n",
    "    desc = HOF_HOG(Input, interest_Harris_points_test[i], 9, n, m)\n",
    "    desc_HOF_HOG_Harris_test.append(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f884944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words for Harris/HOF_HOG\n",
    "bow_train_HOF_HOG_Harris, bow_test_HOF_HOG_Harris = bag_of_words(desc_HOF_HOG_Harris_train, desc_HOF_HOG_Harris_test, 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabor/HOG descriptors for training videos\n",
    "interest_Gabor_points_training = []\n",
    "desc_HOG_Gabor_train = []\n",
    "for Input in training_videos:\n",
    "    interest_points = Gabor_points(Input, sigma, tau, N)\n",
    "    interest_Gabor_points_training.append(interest_points)\n",
    "    desc = HOG(Input, interest_points, 9, n, m)\n",
    "    desc_HOG_Gabor_train.append(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_Gabor_points_test = []\n",
    "desc_HOG_Gabor_test = []\n",
    "for Input in test_videos:\n",
    "    interest_points = Gabor_points(Input, sigma, tau, N)\n",
    "    interest_Gabor_points_test.append(interest_points)\n",
    "    desc = HOG(Input, interest_points, 9, n, m)\n",
    "    desc_HOG_Gabor_test.append(desc)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09290df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words for Gabor/HOG\n",
    "bow_train_HOG_Gabor, bow_test_HOG_Gabor = bag_of_words(desc_HOG_Gabor_train, desc_HOG_Gabor_test, 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_HOF_Gabor_train = []\n",
    "i = 0\n",
    "for Input in training_videos:\n",
    "    desc = HOF(Input, interest_Gabor_points_training[i], 9, n, m)\n",
    "    desc_HOF_Gabor_train.append(desc)\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "desc_HOF_Gabor_test = []\n",
    "for Input in test_videos:\n",
    "    desc = HOF(Input, interest_Gabor_points_test[i], 9, n, m)\n",
    "    desc_HOF_Gabor_test.append(desc)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words for Gabor/HOF\n",
    "bow_train_HOF_Gabor, bow_test_HOF_Gabor = bag_of_words(desc_HOF_Gabor_train, desc_HOF_Gabor_test, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc193e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_HOF_HOG_Gabor_train = []\n",
    "i = 0\n",
    "for Input in training_videos:\n",
    "    desc = HOF_HOG(Input, interest_Gabor_points_training[i], 9, n, m)\n",
    "    desc_HOF_HOG_Gabor_train.append(desc)\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "desc_HOF_HOG_Gabor_test = []\n",
    "for Input in test_videos:\n",
    "    desc = HOF_HOG(Input, interest_Gabor_points_test[i], 9, n, m)\n",
    "    desc_HOF_HOG_Gabor_test.append(desc)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fe3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_HOF_HOG_Gabor, bow_test_HOF_HOG_Gabor = bag_of_words(desc_HOF_HOG_Gabor_train, desc_HOF_HOG_Gabor_test, 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39049cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = 'detector:\\tHarris \\ndescriptor:\\tHOF_HOG_Gabor'\n",
    "bow_train = bow_train_HOG_Harris\n",
    "bow_test = bow_test_HOG_Harris\n",
    "accuracy, pred = svm_train_test(bow_train, training_labels, bow_test, test_labels)\n",
    "print('\\033[1m' + combo + '\\033[0m')\n",
    "print()\n",
    "print('The accuracy for the combination is ' + str(format(accuracy*100, \".3f\")) + \"%\")\n",
    "print()\n",
    "print(\"Here is a table with detailed results:\")\n",
    "print()\n",
    "k = test_videos_name\n",
    "a = test_labels\n",
    "b = pred\n",
    "c = a == b\n",
    "print(\"Video Name \\t \\t \\t Correct Prediction\")\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(k[i] + '\\t ' + a[i] + '\\t ' + b[i]+ '\\t ' + str(c[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = 'detector:\\tHarris \\ndescriptor:\\tHOF'\n",
    "bow_train = bow_train_HOF_Harris\n",
    "bow_test = bow_test_HOF_Harris\n",
    "accuracy, pred = svm_train_test(bow_train, training_labels, bow_test, test_labels)\n",
    "print('\\033[1m' + combo + '\\033[0m')\n",
    "print()\n",
    "print('The accuracy for the combination is ' + str(format(accuracy*100, \".3f\")) + \"%\")\n",
    "print()\n",
    "print(\"Here is a table with detailed results:\")\n",
    "print()\n",
    "k = test_videos_name\n",
    "a = test_labels\n",
    "b = pred\n",
    "c = a == b\n",
    "print(\"Video Name \\t \\t \\t Correct Prediction\")\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(k[i] + '\\t ' + a[i] + '\\t ' + b[i]+ '\\t ' + str(c[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf540734",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = 'detector:\\tHarris \\ndescriptor:\\tHOF and HOG'\n",
    "bow_train = bow_train_HOF_HOG_Harris\n",
    "bow_test = bow_test_HOF_HOG_Harris\n",
    "accuracy, pred = svm_train_test(bow_train, training_labels, bow_test, test_labels)\n",
    "print('\\033[1m' + combo + '\\033[0m')\n",
    "print()\n",
    "print('The accuracy for the combination is ' + str(format(accuracy*100, \".3f\")) + \"%\")\n",
    "print()\n",
    "print(\"Here is a table with detailed results:\")\n",
    "print()\n",
    "k = test_videos_name\n",
    "a = test_labels\n",
    "b = pred\n",
    "c = a == b\n",
    "print(\"Video Name \\t \\t \\t Correct Prediction\")\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(k[i] + '\\t ' + a[i] + '\\t ' + b[i]+ '\\t ' + str(c[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = 'detector:\\tGabor \\ndescriptor:\\tHOG'\n",
    "bow_train = bow_train_HOG_Gabor\n",
    "bow_test = bow_test_HOG_Gabor\n",
    "accuracy, pred = svm_train_test(bow_train, training_labels, bow_test, test_labels)\n",
    "print('\\033[1m' + combo + '\\033[0m')\n",
    "print()\n",
    "print('The accuracy for the combination is ' + str(format(accuracy*100, \".3f\")) + \"%\")\n",
    "print()\n",
    "print(\"Here is a table with detailed results:\")\n",
    "print()\n",
    "k = test_videos_name\n",
    "a = test_labels\n",
    "b = pred\n",
    "c = a == b\n",
    "print(\"Video Name \\t \\t \\t Correct Prediction\")\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(k[i] + '\\t ' + a[i] + '\\t ' + b[i]+ '\\t ' + str(c[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66969472",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = 'detector:\\tGabor \\ndescriptor:\\tHOF'\n",
    "bow_train = bow_train_HOF_Gabor\n",
    "bow_test = bow_test_HOF_Gabor\n",
    "accuracy, pred = svm_train_test(bow_train, training_labels, bow_test, test_labels)\n",
    "print('\\033[1m' + combo + '\\033[0m')\n",
    "print()\n",
    "print('The accuracy for the combination is ' + str(format(accuracy*100, \".3f\")) + \"%\")\n",
    "print()\n",
    "print(\"Here is a table with detailed results:\")\n",
    "print()\n",
    "k = test_videos_name\n",
    "a = test_labels\n",
    "b = pred\n",
    "c = a == b\n",
    "print(\"Video Name \\t \\t \\t Correct Prediction\")\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(k[i] + '\\t ' + a[i] + '\\t ' + b[i]+ '\\t ' + str(c[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7bd32f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow_train_HOF_HOG_Gabor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26893/2881785152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcombo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'detector:\\tGabor \\ndescriptor:\\tHOF and HOG'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_train_HOF_HOG_Gabor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbow_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_test_HOF_HOG_Gabor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[1m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcombo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\033[0m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow_train_HOF_HOG_Gabor' is not defined"
     ]
    }
   ],
   "source": [
    "combo = 'detector:\\tGabor \\ndescriptor:\\tHOF and HOG'\n",
    "bow_train = bow_train_HOF_HOG_Gabor\n",
    "bow_test = bow_test_HOF_HOG_Gabor\n",
    "accuracy, pred = svm_train_test(bow_train, training_labels, bow_test, test_labels)\n",
    "print('\\033[1m' + combo + '\\033[0m')\n",
    "print()\n",
    "print('The accuracy for the combination is ' + str(format(accuracy*100, \".3f\")) + \"%\")\n",
    "print()\n",
    "print(\"Here is a table with detailed results:\")\n",
    "print()\n",
    "k = test_videos_name\n",
    "a = test_labels\n",
    "b = pred\n",
    "c = a == b\n",
    "print(\"Video Name \\t \\t \\t Correct Prediction\")\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(k[i] + '\\t ' + a[i] + '\\t ' + b[i]+ '\\t ' + str(c[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af522ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe56e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deeae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464cbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3876f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
